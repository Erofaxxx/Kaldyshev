# АНАЛИЗ ЗАВИСИМОСТЕЙ ДЛЯ ЛАБОРАТОРНОЙ РАБОТЫ

## Условия Бернстайна

Для параллельного выполнения двух операторов S1 и S2 должны выполняться условия:
1. IN(S1) ∩ OUT(S2) = ∅ (нет антизависимостей)
2. OUT(S1) ∩ IN(S2) = ∅ (нет истинных зависимостей)
3. OUT(S1) ∩ OUT(S2) = ∅ (нет зависимостей по выходу)

## Эталонная программа

```c
for (i=0; i<ISIZE; i++){
    for (j = 0; j < JSIZE; j++){
        a[i][j] = sin(2*a[i][j]);
    }
}
```

**Вектор направления:** <0, 0> (нет зависимостей)
**Вектор расстояния:** (0, 0)

**Анализ:**
- Чтение: a[i][j]
- Запись: a[i][j]
- Зависимость только в пределах одной итерации
- **Тип:** Независимые итерации

**Распараллеливание:**
- Можно распараллелить как внешний, так и внутренний цикл
- Оптимально: распараллелить внешний цикл (по строкам)
- Ожидается: линейное ускорение

---

## Задача 1е (MPI)

```c
for (i=1; i<ISIZE; i++){
    for (j = 8; j < JSIZE; j++){
        a[i][j] = sin(5*a[i-1][j-8]);
    }
}
```

**Вектор направления:** <1, 8>
**Вектор расстояния:** (1, 8)

**Анализ:**
- Чтение: a[i-1][j-8]
- Запись: a[i][j]
- Зависимость: итерация (i, j) зависит от (i-1, j-8)
- **Тип:** Истинная зависимость (flow dependence)

**Распараллеливание:**
- Внешний цикл (по i): НЕЛЬЗЯ напрямую (зависимость по i)
- Внутренний цикл (по j): МОЖНО (независимые элементы в строке)
- Альтернатива: распараллеливание по диагоналям (wavefront)

**Стратегия:**
1. Распределить строки между процессами
2. Каждый процесс последовательно обрабатывает свои строки
3. Передавать граничные данные между процессами
4. Ускорение ограничено зависимостями

---

## Задача 2г (OpenMP)

```c
for (i=0; i<ISIZE-3; i++){
    for (j = 2; j < JSIZE; j++){
        a[i][j] = sin(0.1*a[i+3][j-2]);
    }
}
```

**Вектор направления:** <-3, 2>
**Вектор расстояния:** (-3, 2)

**Анализ:**
- Чтение: a[i+3][j-2]
- Запись: a[i][j]
- Зависимость: запись в a[i][j], чтение из a[i+3][j-2]
- **Тип:** Антизависимость (anti-dependence)

**Распараллеливание:**
- Внешний цикл (по i): МОЖНО (каждая строка i читает из i+3)
- Внутренний цикл (по j): МОЖНО
- При правильном порядке записи антизависимости не нарушаются

**Стратегия:**
1. Распараллелить внешний цикл с OpenMP
2. Использовать `#pragma omp parallel for`
3. Каждый поток обрабатывает свои строки
4. Ожидается хорошее ускорение

---

## Задача 3ж (MPI)

```c
for (i=0; i<ISIZE; i++){
    for (j = 0; j < JSIZE; j++){
        a[i][j] = sin(0.1*a[i][j]);
    }
}
for (i=0; i<ISIZE-1; i++){
    for (j = 2; j < JSIZE; j++){
        b[i][j] = a[i+1][j-2]*1.5;
    }
}
```

### Первый цикл:
**Вектор направления:** <0, 0>
**Тип:** Независимые итерации
**Распараллеливание:** Легко распараллеливается по строкам

### Второй цикл:
**Вектор направления:** <-1, 2> (относительно массива a)
**Тип:** Чтение из a, запись в b (нет конфликтов)
**Распараллеливание:** Легко распараллеливается

**Общая стратегия:**
1. Оба цикла независимы друг от друга (второй зависит только от результата первого)
2. Каждый цикл можно распараллелить по строкам
3. Распределить строки между MPI процессами
4. Учесть обмен граничными данными для второго цикла
5. Ожидается хорошее ускорение

---

## Выводы по распараллеливанию

### Эффективность распараллеливания (ожидаемая):
1. **Эталонная программа**: ★★★★★ (отличная)
2. **Задача 2г**: ★★★★☆ (хорошая)
3. **Задача 3ж**: ★★★★☆ (хорошая)
4. **Задача 1е**: ★★★☆☆ (средняя, ограничена зависимостями)

### Факторы, влияющие на ускорение:
- Накладные расходы на коммуникацию (MPI)
- Накладные расходы на создание потоков (OpenMP)
- Балансировка нагрузки между процессами/потоками
- Размер задачи (5000x5000 достаточно велик для эффективного распараллеливания)
- Зависимости между итерациями
